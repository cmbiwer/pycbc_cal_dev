#! /usr/bin/python

# Copyright (C) 2014 Christopher M. Biwer
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Generals
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

import argparse
import h5py
import logging
import numpy as np
import sqlite3
import sys

from glue.ligolw import dbtables
from pycbc import pnutils

# initializations
filename_db = 'test.db'
filename_tmpltbank = '/home/ahnitz/projects/BNS/snrthreshold/mdc/ns/SNR_5.0/bank/H1L1-BANK2HDF-966384015-1000000.hdf'
filenames_sngl = ['/home/ahnitz/projects/BNS/snrthreshold/mdc/ns/SNR_5.0/full_data/H1-HDF_TRIGGER_MERGE_FULL_DATA-966384015-1000000.hdf',
                  '/home/ahnitz/projects/BNS/snrthreshold/mdc/ns/SNR_5.0/full_data/L1-HDF_TRIGGER_MERGE_FULL_DATA-966384015-1000000.hdf']
filename_coinc = '/home/ahnitz/projects/BNS/snrthreshold/mdc/ns/SNR_5.0/full_data/H1L1-STATMAP_FULL_DATA_FULL_12H-966384015-1000000.hdf'
filenames_inj = ['']
filenames_segments = ''
filenames_vetoes  = ['']

def sqlite_create_table(table):
    """
    Creates a LIGOLW table in the database.
    """

    # get table name and columns
    table_name   = table.tableName.replace(':table', '')
    validcolumns = table.validcolumns

    # put columns in a list of tuples where the first element is
    # the column name and the second element is the column type
    columns = []
    for col_name,col_type in validcolumns.iteritems():
        if col_type in ['int_4s', 'int_4u']:
            col_type = 'INTEGER'
        elif col_type in ['real_4', 'real_8']:
            col_type = 'REAL'
        elif col_type in ['ilwd:char', 'lstring', 'char_v']:
            col_type = 'TEXT'
        else:
            logging.info('Unknown column type of '+col_type+' for '+col_name+'.')
            sys.exit()
        columns.append( (col_name, col_type) )

    # create table
    sqlquery = """
    CREATE TABLE %s(%s);
    """%(table_name, ', '.join([col_name+' '+col_type for col_name,col_type in columns]))
    cur.execute(sqlquery)

    # key a dict on the column names
    tmp = {}
    for key in table.validcolumns.keys():
        tmp[key] = None

    return tmp

def sqlite_insert_into_table(table, tmp):
    """
    Adds rows into a LIGOLW table in the database.
    """

    # get table name
    table_name = table.tableName.replace(':table', '')

    # put column names and column arrays into seperate lists
    # that will be used to construct the SQLite command
    column_names  = []
    column_values = []
    for key,val in tmp.iteritems():
        if val is not None:
            column_names.append(key)
            column_values.append(val)

    # check if there are any non-empty columns to be added
    if len(column_names):

        # add rows into table
        sqlquery = """
        INSERT INTO %s(%s) VALUES (%s);
        """%( table_name, ', '.join(column_names), ', '.join(['?'] * len(column_names)) )
        cur.executemany(sqlquery, zip(*column_values))

    # else warning that there were no rows added
    else:
        logging.warn('No rows were added to the %s table...'%table_name)

# parse command line
parser = argparse.ArgumentParser(usage='pycbc_convert_hdf5_sqlite [--options]',
                  description="Read HDF5 files with inspiral, coincidence, \
                  and injection data to produce a sqlite database that obeys \
                  the LIGO schema.")
opts = parser.parse_args()

# create log
logging_level = logging.DEBUG
logging.basicConfig(format='%(asctime)s : %(message)s', level=logging_level)

# create sqlite database
logging.info('Creating database...')
con = sqlite3.connect(filename_db)
con.row_factory = sqlite3.Row
cur = con.cursor()

# tell sqlite3 about numpy int datatypes
for t in (np.int8, np.int16, np.int32, np.int64, np.uint8,
          np.uint16, np.uint32, np.uint64):
   sqlite3.register_adapter(t, long)

# tell sqlite3 about numpy float datatypes
for t in (np.float32,):
   sqlite3.register_adapter(t, float)

###############################################################################
# coinc_event_map
###############################################################################

# read HDF5 coincidence file
data_coinc = h5py.File(filename_coinc, 'r')

# get IFO names
ifo1 = data_coinc.attrs['detector_1']
ifo2 = data_coinc.attrs['detector_2']

# get IFO single inspiral trigger IDs
# FIXME: should not get all data at once but will for dev purposes
num_coinc_trigs = data_coinc['foreground']['trigger_id1'].len()
trigger_ids_1 =data_coinc['foreground']['trigger_id1'][:]
trigger_ids_2 =data_coinc['foreground']['trigger_id2'][:]
template_id = data_coinc['foreground']['template_id'][:]

# create coinc_event_map table in database and a dict with column names as key
logging.info('Creating coinc_event_map table...')
tmp = sqlite_create_table(dbtables.lsctables.CoincMapTable)

# construct an array for event_id
tmp['event_id']  = ['sngl_inspiral:event_id:'+ifo1+':'+str(trigger_ids_1[i]) for i in range(num_coinc_trigs)]
tmp['event_id'] += ['sngl_inspiral:event_id:'+ifo2+':'+str(trigger_ids_2[i]) for i in range(num_coinc_trigs)]
tmp['event_id']  = np.array(tmp['event_id'])

# construct an array for table_name and coinc_event_id
tmp['table_name']     = np.array(['sngl_inspiral' for i in range(num_coinc_trigs)])
tmp['coinc_event_id'] = np.array(['coinc_event:coinc_event_id:'+str(i) for i in range(num_coinc_trigs)])

# insert rows into coinc_event_map table
logging.info('Populating coinc_event_map table...')
sqlite_insert_into_table(dbtables.lsctables.CoincMapTable, tmp)

###############################################################################
# coinc_event
###############################################################################

# create coinc_event table in database and a dict with column names as key
logging.info('Creating coinc_event table...')
tmp = sqlite_create_table(dbtables.lsctables.CoincTable)

# construct an array for coinc_event_id
rows = cur.execute('SELECT coinc_event_id FROM coinc_event_map').fetchall()
tmp['coinc_event_id'] = np.array([row['coinc_event_id'] for row in rows])

# construct an array for instruments
tmp['instruments'] = np.array([','.join([ifo1, ifo2]) for i in range(num_coinc_trigs)])

# construct an array for nevents
tmp['nevents'] = np.array([2 for i in range(num_coinc_trigs)])

# construct an array for process_id
# FIXME: add this, is this used even?

# construct an array for coinc_def_id
# FIXME: add this

# construct an array for time_slide_id
# FIXME: add this

# construct an array likelihood
# likelihood doesn't appear to be populated in old databases

# insert rows into coinc_map table
logging.info('Populating coinc_event table...')
sqlite_insert_into_table(dbtables.lsctables.CoincTable, tmp)

###############################################################################
# coinc_inspiral
###############################################################################

# read HDF5 tmpltbank file
data_tmpltbank = h5py.File(filename_tmpltbank, 'r')

# create coinc_event table in database and a dict with column names as key
logging.info('Creating coinc_inspiral table...')
tmp = sqlite_create_table(dbtables.lsctables.CoincInspiralTable)

# construct an array for coinc_event_id and ifos
rows = cur.execute('SELECT coinc_event_id, instruments FROM coinc_event').fetchall()
tmp['coinc_event_id'] = np.array([row['coinc_event_id'] for row in rows])
tmp['ifos'] = np.array([row['instruments'] for row in rows])

# construct an array for false_alarm_rate
tmp['false_alarm_rate'] = np.array([1./ifar for ifar in data_coinc['foreground']['ifar'][:]])

# construct an array for minimum_duration
# FIXME: add this; is this used?

# construct an array for mass and mchirp
template_id = data_coinc['foreground']['template_id'][:]
mass1 = data_tmpltbank['mass1'][:][template_id]
mass2 = data_tmpltbank['mass2'][:][template_id]
tmp['mass'] = mass1 + mass2
tmp['mchirp'] = [pnutils.mass1_mass2_to_mchirp_eta(mass1, mass2)[0] for mass1,mass2 in zip(mass1,mass2)]

# construct an array for end_time and end_time_ns
# FIXME: add this

# construct an array for combined_far
# FIXME: add this

# insert rows into coinc_inspiral table
logging.info('Populating coinc_inspiral table...')
sqlite_insert_into_table(dbtables.lsctables.CoincInspiralTable, tmp)

###############################################################################
# sngl_inspiral
###############################################################################

# create coinc_event table in database and a dict with column names as key
logging.info('Creating sngl_inspiral table...')
tmp1 = sqlite_create_table(dbtables.lsctables.SnglInspiralTable)
tmp2 = tmp1

# make lists of IFO-dependent data to index
# FIXME: this needs to be more robust for n detectors
ifo_list = [ifo1, ifo2]
trigger_id_list = [trigger_ids_1, trigger_ids_2]
tmp_list = [tmp1, tmp2]

# loop over IFO IDs
for i in range(len(ifo_list)):

    # read HDF5 tmpltbank file
    data_sngl = h5py.File(filenames_sngl[i], 'r')

    # get IFO-dependent data
    ifo = ifo_list[i]
    trigger_id = trigger_id_list[i]
    tmp = tmp_list[i]

    # construct an array for event_id
    tmp['event_id']  = ['sngl_inspiral:event_id:'+ifo+':'+str(trigger_id[i]) for i in range(num_coinc_trigs)]

    # construct an array for ifo
    tmp['ifo'] = np.array([ifo for j in range(num_coinc_trigs)])

    # construct an array for end_time and end_time_ns
    end_time = data_sngl[ifo]['end_time'][:][trigger_id]
    tmp['end_time'] = np.array([int(time) for time in end_time])
    tmp['end_time_ns'] = np.array([int(time % 1 * 1e9) for time in end_time])

    # construct an array for chi-squared values and their degrees of freedom
    tmp['cont_chisq'] = data_sngl[ifo]['cont_chisq'][:][trigger_id]
    tmp['cont_chisq_dof'] = map(int, data_sngl[ifo]['cont_chisq_dof'][:][trigger_id])
    tmp['bank_chisq'] = data_sngl[ifo]['bank_chisq'][:][trigger_id]
    tmp['bank_chisq_dof'] = map(int, data_sngl[ifo]['bank_chisq_dof'][:][trigger_id])
    tmp['chisq'] = data_sngl[ifo]['chisq_dof'][:][trigger_id]
    tmp['chisq_dof'] = map(int, data_sngl[ifo]['chisq_dof'][:][trigger_id])

    # construct an array for snr
    tmp['snr'] = data_sngl[ifo]['snr'][:][trigger_id]

    # construct an array for coa_phase
    tmp['coa_phase'] = data_sngl[ifo]['coa_phase'][:][trigger_id]

    # construct an array for sigmasq
    tmp['sigmasq'] = data_sngl[ifo]['sigmasq'][:][trigger_id]

    # construct an array for mass quantities
    template_id = data_sngl[ifo]['template_id'][:][trigger_id]
    tmp['mass1'] = data_tmpltbank['mass1'][:][template_id]
    tmp['mass2'] = data_tmpltbank['mass2'][:][template_id]
    tmp['mtotal'] = tmp['mass1'] + tmp['mass2']
    tmp['mchirp'] = [pnutils.mass1_mass2_to_mchirp_eta(mass1, mass2)[0] for mass1,mass2 in zip(tmp['mass1'],tmp['mass2'])]
    tmp['eta'] = [pnutils.mass1_mass2_to_mchirp_eta(mass1, mass2)[1] for mass1,mass2 in zip(tmp['mass1'],tmp['mass2'])]

    # construct an array for spin quantities
    # FIXME: only spin-z were in test files, need to add case where they don't exist
    tmp['spin1z'] = data_tmpltbank['spin1z'][:][template_id]
    tmp['spin2z'] = data_tmpltbank['spin2z'][:][template_id]

    # construct an array for tau quantities
    # FIXME: can use pnuutils.mass1_mass2_to_tau0_tau3 but need f_low; are these tau quantities used?

    # construct an array for effective distance 
    tmp['eff_distance'] = tmp['sigmasq']**(0.5) / abs(tmp['snr'])

    # insert rows into sngl_inspiral table
    logging.info('Populating sngl_inspiral table...')
    sqlite_insert_into_table(dbtables.lsctables.SnglInspiralTable, tmp)

# remove intermediate arrays
del end_time

###############################################################################
# time_slide
###############################################################################

# create time_slide table in database and a dict with column names as key
logging.info('Creating time_slide table...')
tmp = sqlite_create_table(dbtables.lsctables.TimeSlideTable)

# construct an array for the IFO
num_bkg_trigs = data_coinc['background']['trigger_id1'].len()
tmp['instrument'] = np.array([','.join([ifo1, ifo2]) for i in range(num_bkg_trigs)]) 

# construct an array for the offset of the time slide
tmp['offset'] = data_coinc['background']['timeslide_id'][:]

# construct an array for the time slide ID
tmp['time_slide_id'] = np.array(['time_slide:time_slide_id:'+str(timeslide) for timeslide in data_coinc['background']['timeslide_id'][:]])

# insert rows into time_slide table
logging.info('Populating time_slide table...')
sqlite_insert_into_table(dbtables.lsctables.TimeSlideTable, tmp)

###############################################################################
# experiment
###############################################################################

# create coinc_event table in database and a dict with column names as key
logging.info('Creating experiment table...')
tmp = sqlite_create_table(dbtables.lsctables.ExperimentTable)

# construct an array experiment ID, each experiment is an IFO combination
# FIXME: this entire section assumes only a 2-detector analysis
tmp['experiment_id'] = ['experiment:experiment_id:0']

# construct an array for the IFOs in the experiment
tmp['instruments'] = [','.join(ifo_list)]

# construct an array for the start and end time of the experiment
# FIXME: are these the correct times?
tmp['gps_start_time'] = [0]
tmp['gps_end_time'] = [0]

# insert rows into experiment table
logging.info('Populating experiment table...')
sqlite_insert_into_table(dbtables.lsctables.ExperimentTable, tmp)

###############################################################################
# experiment_summary
###############################################################################

# create coinc_event table in database and a dict with column names as key
logging.info('Creating experiment_summary table...')
tmp = sqlite_create_table(dbtables.lsctables.ExperimentSummaryTable)

# construct an array for the experiment_summ_id
num_slides = data_coinc.attrs['num_slides']
tmp['experiment_summ_id'] = np.array(['experiment_summary:experiment_summ_id:'+str(i) for i in range(num_slides+1)])

# construct an array for the duration of the experiment
# FIXME: add this

# construct an array for the time slide ID
rows = cur.execute('SELECT DISTINCT time_slide_id FROM time_slide').fetchall()
tmp['time_slide_id']  = ['time_slide:time_slide_id:0']
tmp['time_slide_id'] += [row['time_slide_id'] for row in rows]
tmp['time_slide_id']  = np.array(tmp['time_slide_id'])

# construct an array for the experiment datatype
# all_data : a zero-lag experiment
# slide    : a time slide experiment
tmp['datatype']  = ['all_data']
tmp['datatype'] += ['slide' for i in range(num_slides)]
tmp['datatype']  = np.array(tmp['datatype'])

# insert rows into experiment table
logging.info('Populating experiment_summary table...')
sqlite_insert_into_table(dbtables.lsctables.ExperimentSummaryTable, tmp)

# sav edatabasi and exit
logging.info('Done.')
con.commit()
con.close()
sys.exit()




#########################################

# Some notes:

# Need these tables:
#coinc_definer       experiment_map      search_summary      sim_inspiral      
#coinc_event         experiment_summary  search_summvars     sngl_inspiral     
#coinc_event_map     filter              segment             summ_value        
#coinc_inspiral      process             segment_definer     time_slide        
#experiment          process_params      segment_summary     veto_definer    

