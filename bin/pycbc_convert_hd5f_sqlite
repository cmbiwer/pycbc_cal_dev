#! /usr/bin/python

# Copyright (C) 2014 Christopher M. Biwer
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Generals
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

import argparse
import h5py
import logging
import numpy as np
import sqlite3
import sys

from glue.ligolw import dbtables
from pycbc import pnutils

# initializations
filename_db = 'test.db'
filename_tmpltbank = '/home/ahnitz/projects/BNS/snrthreshold/mdc/ns/SNR_6.0/bank/H1L1-BANK2HDF-966384015-1000000.hdf'
filenames_sngl = ['/home/ahnitz/projects/BNS/snrthreshold/mdc/ns/SNR_6.0/full_data/H1-HDF_TRIGGER_MERGE_FULL_DATA-966384015-1000000.hdf',
                  '/home/ahnitz/projects/BNS/snrthreshold/mdc/ns/SNR_6.0/full_data/L1-HDF_TRIGGER_MERGE_FULL_DATA-966384015-1000000.hdf']
filename_coinc = '/home/cbiwer/src/H1L1-STATMAP_FULL_DATA_FULL_12H_SMALL-966384015-1000000.hdf'
filenames_inj = ['']
filenames_segments = ''
filenames_vetoes  = ['']

def sqlite_create_table(table):
    """
    Creates a LIGOLW table in the database.
    """

    # get table name and columns
    table_name   = table.tableName.replace(':table', '')
    validcolumns = table.validcolumns

    # put columns in a list of tuples where the first element is
    # the column name and the second element is the column type
    columns = []
    for col_name,col_type in validcolumns.iteritems():
        if col_type in ['int_4s', 'int_4u']:
            col_type = 'INTEGER'
        elif col_type in ['real_4', 'real_8']:
            col_type = 'REAL'
        elif col_type in ['ilwd:char', 'lstring', 'char_v']:
            col_type = 'TEXT'
        else:
            logging.info('Unknown column type of '+col_type+' for '+col_name+'.')
            sys.exit()
        columns.append( (col_name, col_type) )

    # create table
    sqlquery = """
    CREATE TABLE %s(%s);
    """%(table_name, ', '.join([col_name+' '+col_type for col_name,col_type in columns]))
    cur.execute(sqlquery)

    # key a dict on the column names
    tmp = {}
    for key in table.validcolumns.keys():
        tmp[key] = None

    return tmp

def sqlite_insert_into_table(table, tmp):
    """
    Adds rows into a LIGOLW table in the database.
    """

    # get table name
    table_name = table.tableName.replace(':table', '')

    # put column names and column arrays into seperate lists
    # that will be used to construct the SQLite command
    column_names  = []
    column_values = []
    for key,val in tmp.iteritems():
        if val is not None:
            column_names.append(key)
            column_values.append(val)

    # check if there are any non-empty columns to be added
    if len(column_names):

        # add rows into table
        sqlquery = """
        INSERT INTO %s(%s) VALUES (%s);
        """%( table_name, ', '.join(column_names), ', '.join(['?'] * len(column_names)) )
        cur.executemany(sqlquery, zip(*column_values))

    # else warning that there were no rows added
    else:
        logging.warn('No rows were added to the %s table...'%table_name)

# parse command line
parser = argparse.ArgumentParser(usage='pycbc_convert_hdf5_sqlite [--options]',
                  description="Read HDF5 files with inspiral, coincidence, \
                  and injection data to produce a sqlite database that obeys \
                  the LIGO schema.")
opts = parser.parse_args()

# create log
logging_level = logging.DEBUG
logging.basicConfig(format='%(asctime)s : %(message)s', level=logging_level)

# create sqlite database
logging.info('Creating database...')
con = sqlite3.connect(filename_db)
con.row_factory = sqlite3.Row
cur = con.cursor()

# tell sqlite3 about numpy int datatypes
for t in (np.int8, np.int16, np.int32, np.int64, np.uint8,
          np.uint16, np.uint32, np.uint64):
   sqlite3.register_adapter(t, long)

# tell sqlite3 about numpy float datatypes
for t in (np.float32,):
   sqlite3.register_adapter(t, float)

# read HDF5 coincidence file
data_coinc = h5py.File(filename_coinc, 'r')

# get IFO names
ifo1 = data_coinc.attrs['detector_1']
ifo2 = data_coinc.attrs['detector_2']

# get names of datasets
dataset_list = ['foreground', 'background']

# create coinc_event_map table in database and a dict with column names as key
logging.info('Creating coinc_event_map table...')
coinc_event_map = sqlite_create_table(dbtables.lsctables.CoincMapTable)

# create coinc_event table in database and a dict with column names as key
logging.info('Creating coinc_event table...')
coinc_event = sqlite_create_table(dbtables.lsctables.CoincTable)

# create coinc_event table in database and a dict with column names as key
logging.info('Creating coinc_inspiral table...')
coinc_inspiral = sqlite_create_table(dbtables.lsctables.CoincInspiralTable)

# create coinc_event table in database and a dict with column names as key
logging.info('Creating sngl_inspiral table...')
sngl_inspiral = sqlite_create_table(dbtables.lsctables.SnglInspiralTable)

# create time_slide table in database and a dict with column names as key
logging.info('Creating time_slide table...')
time_slide = sqlite_create_table(dbtables.lsctables.TimeSlideTable)

# create experiment_map table in database and a dict with column names as key
logging.info('Creating experiment_map table...')
experiment_map = sqlite_create_table(dbtables.lsctables.ExperimentMapTable)

# create coinc_event table in database and a dict with column names as key
logging.info('Creating experiment_summary table...')
experiment_summary = sqlite_create_table(dbtables.lsctables.ExperimentSummaryTable)

# loop to add both foreground and background
for dataset in dataset_list:

    ###############################################################################
    # coinc_event_map
    ###############################################################################

    # print
    logging.info('Constructing arrays for %s rows in the coinc_event_map table...'%dataset)

    # get number of coincident triggers and IFO single inspiral trigger IDs
    num_coinc_trigs = data_coinc[dataset]['trigger_id1'].len()
    trigger_id1 = data_coinc[dataset]['trigger_id1'][:]
    trigger_id2 = data_coinc[dataset]['trigger_id2'][:]
    template_id = data_coinc[dataset]['template_id'][:]

    # construct an array for event_id
    event_id1 = ['sngl_inspiral:event_id:'+dataset+':'+ifo1+':'+str(trigger_id1[i]) for i in range(num_coinc_trigs)]
    event_id2 = ['sngl_inspiral:event_id:'+dataset+':'+ifo2+':'+str(trigger_id2[i]) for i in range(num_coinc_trigs)]
    coinc_event_map['event_id']  = np.array(event_id1 + event_id2)

    # construct an array for table_name and coinc_event_id
    coinc_event_map['table_name']     = np.array(['sngl_inspiral' for i in range(num_coinc_trigs)])
    coinc_event_map['coinc_event_id'] = np.array(['coinc_event:coinc_event_id:'+dataset+':'+str(i) for i in range(num_coinc_trigs)])

    # insert rows into coinc_event_map table
    logging.info('Populating %s rows in the coinc_event_map table...'%dataset)
    sqlite_insert_into_table(dbtables.lsctables.CoincMapTable, coinc_event_map)

    # make lists of IFO-dependent data to index
    # FIXME: this needs to be more robust for n detectors
    ifo_list = [ifo1, ifo2]
    trigger_id_list = [trigger_id1, trigger_id2]
    event_id_list = [event_id1, event_id2]

    ###############################################################################
    # coinc_event
    ###############################################################################

    # print
    logging.info('Constructing arrays for %s rows in the coinc_event_map table...'%dataset)

    # construct an array for instruments
    coinc_event['instruments'] = np.array([','.join([ifo1, ifo2]) for i in range(num_coinc_trigs)])

    # construct an array for nevents
    coinc_event['nevents'] = np.array([2 for i in range(num_coinc_trigs)])

    # construct an array for process_id
    # FIXME: add this; is this used even?

    # construct an array for coinc_def_id
    # FIXME: add this

    # construct an array for time_slide_id
    if dataset == 'background':
        coinc_event['time_slide_id'] = np.array(['time_slide:time_slide_id:'+str(timeslide) for timeslide in data_coinc[dataset]['timeslide_id'][:]])
    else:
        coinc_event['time_slide_id'] = np.array(['time_slide:time_slide_id:0' for i in range(num_coinc_trigs)])

    # insert rows into coinc_map table
    logging.info('Populating %s rows in the coinc_event table...'%dataset)
    sqlite_insert_into_table(dbtables.lsctables.CoincTable, coinc_event)

    ###############################################################################
    # coinc_inspiral
    ###############################################################################

    # print
    logging.info('Constructing arrays for %s rows in the coinc_inspiral table...'%dataset)

    # read HDF5 tmpltbank file
    data_tmpltbank = h5py.File(filename_tmpltbank, 'r')

    # construct an array for coinc_event_id and ifos
    coinc_inspiral['coinc_event_id'] = coinc_event_map['event_id']
    coinc_inspiral['ifos'] = coinc_event['instruments']

    # construct an array for false_alarm_rate
    coinc_inspiral['false_alarm_rate'] = np.array([1./ifar for ifar in data_coinc[dataset]['ifar'][:]])

    # construct an array for minimum_duration
    # FIXME: add this; is this used?

    # construct an array for mass and mchirp
    template_id = data_coinc[dataset]['template_id'][:]
    mass1 = data_tmpltbank['mass1'][:][template_id]
    mass2 = data_tmpltbank['mass2'][:][template_id]
    coinc_inspiral['mass'] = mass1 + mass2
    coinc_inspiral['mchirp'] = [pnutils.mass1_mass2_to_mchirp_eta(mass1, mass2)[0] for mass1,mass2 in zip(mass1,mass2)]

    # construct an array for end_time and end_time_ns
    # FIXME: add this

    # construct an array for combined_far
    # FIXME: add this

    # insert rows into coinc_inspiral table
    logging.info('Populating %s rows in the coinc_inspiral table...'%dataset)
    sqlite_insert_into_table(dbtables.lsctables.CoincInspiralTable, coinc_inspiral)

    ###############################################################################
    # sngl_inspiral
    ###############################################################################

    # loop over IFO IDs
    for i in range(len(ifo_list)):

        # read HDF5 tmpltbank file
        data_sngl = h5py.File(filenames_sngl[i], 'r')

        # get IFO-dependent data
        ifo = ifo_list[i]
        trigger_id = trigger_id_list[i]

        # print
        logging.info('Constructing arrays for %s %s rows in the sngl_inspiral table...'%(ifo, dataset))

        # construct an array for event_id
        sngl_inspiral['event_id']  = event_id_list[i]

        # construct an array for ifo
        sngl_inspiral['ifo'] = np.array([ifo for j in range(num_coinc_trigs)])

        # construct an array for end_time and end_time_ns
        end_time = data_sngl[ifo]['end_time'][:][trigger_id]
        sngl_inspiral['end_time'] = np.array([int(time) for time in end_time])
        sngl_inspiral['end_time_ns'] = np.array([int(time % 1 * 1e9) for time in end_time])

        # construct an array for chi-squared values and their degrees of freedom
        sngl_inspiral['cont_chisq'] = data_sngl[ifo]['cont_chisq'][:][trigger_id]
        sngl_inspiral['cont_chisq_dof'] = map(int, data_sngl[ifo]['cont_chisq_dof'][:][trigger_id])
        sngl_inspiral['bank_chisq'] = data_sngl[ifo]['bank_chisq'][:][trigger_id]
        sngl_inspiral['bank_chisq_dof'] = map(int, data_sngl[ifo]['bank_chisq_dof'][:][trigger_id])
        sngl_inspiral['chisq'] = data_sngl[ifo]['chisq_dof'][:][trigger_id]
        sngl_inspiral['chisq_dof'] = map(int, data_sngl[ifo]['chisq_dof'][:][trigger_id])

        # construct an array for snr
        sngl_inspiral['snr'] = data_sngl[ifo]['snr'][:][trigger_id]

        # construct an array for coa_phase
        sngl_inspiral['coa_phase'] = data_sngl[ifo]['coa_phase'][:][trigger_id]

        # construct an array for sigmasq
        sngl_inspiral['sigmasq'] = data_sngl[ifo]['sigmasq'][:][trigger_id]

        # construct an array for mass quantities
        template_id = data_sngl[ifo]['template_id'][:][trigger_id]
        sngl_inspiral['mass1'] = data_tmpltbank['mass1'][:][template_id]
        sngl_inspiral['mass2'] = data_tmpltbank['mass2'][:][template_id]
        sngl_inspiral['mtotal'] = sngl_inspiral['mass1'] + sngl_inspiral['mass2']
        sngl_inspiral['mchirp'] = [pnutils.mass1_mass2_to_mchirp_eta(mass1, mass2)[0] for mass1,mass2 in zip(sngl_inspiral['mass1'],sngl_inspiral['mass2'])]
        sngl_inspiral['eta'] = [pnutils.mass1_mass2_to_mchirp_eta(mass1, mass2)[1] for mass1,mass2 in zip(sngl_inspiral['mass1'],sngl_inspiral['mass2'])]

        # construct an array for spin quantities
        # FIXME: only spin-z were in test files, need to add case where they don't exist
        sngl_inspiral['spin1z'] = data_tmpltbank['spin1z'][:][template_id]
        sngl_inspiral['spin2z'] = data_tmpltbank['spin2z'][:][template_id]

        # construct an array for tau quantities
        # FIXME: can use pnuutils.mass1_mass2_to_tau0_tau3 but need f_low; are these tau quantities used?

        # construct an array for effective distance 
        sngl_inspiral['eff_distance'] = sngl_inspiral['sigmasq']**(0.5) / abs(sngl_inspiral['snr'])

        # insert rows into sngl_inspiral table
        logging.info('Populating sngl_inspiral table...')
        sqlite_insert_into_table(dbtables.lsctables.SnglInspiralTable, sngl_inspiral)

    # remove intermediate arrays no longer needed
    del end_time

    ###############################################################################
    # time_slide
    ###############################################################################

    # print
    logging.info('Constructing arrays for %s rows in the time_slide table...'%dataset)

    # construct an array for the IFO
    time_slide['instrument'] = np.array([','.join([ifo1, ifo2]) for j in range(num_coinc_trigs)])

    # construct an array for the offset of the time slide
    if dataset == 'background':
        time_slide['offset'] = data_coinc[dataset]['timeslide_id'][:]
    else:
        time_slide['offset'] = np.array([0 for j in range(num_coinc_trigs)])

    # construct an array for the time slide ID
    time_slide['time_slide_id'] = coinc_event['time_slide_id']

    # insert rows into time_slide table
    logging.info('Populating time_slide table...')
    sqlite_insert_into_table(dbtables.lsctables.TimeSlideTable, time_slide)

    ###############################################################################
    # experiment_map
    ###############################################################################

    # print
    logging.info('Constructing arrays for %s rows in the experiment_map table...'%dataset)

    # construct an array for experiment_summ_id
    if dataset == 'background':
        experiment_map['experiment_summ_id'] = np.array(['experiment_summary:experiment_summ_id:'+str(timeslide) for timeslide in data_coinc[dataset]['timeslide_id'][:]])
    else:
        experiment_map['experiment_summ_id'] = np.array(['experiment_summary:experiment_summ_id:0' for i in range(num_coinc_trigs)])

    # construct an array for the coinc_event_id
    experiment_map['coinc_event_id'] = coinc_event_map['event_id'] 

    # insert rows into experiment table
    logging.info('Populating experiment_summary table...')
    sqlite_insert_into_table(dbtables.lsctables.ExperimentMapTable, experiment_map)

    ###############################################################################
    # experiment_summary
    ###############################################################################

    # print
    logging.info('Constructing arrays for %s rows in the experiment_summary table...'%dataset)

    # construct an array for the experiment_summ_id
    experiment_summary['experiment_summ_id'] = experiment_map['experiment_summ_id']

    # construct an array for the duration of the experiment
    # FIXME: this needs to be added but right now this is a dummy value
    experiment_summary['duration'] = np.array([4 for i in range(len(time_slide['time_slide_id']))])

    # construct an array for the time slide ID
    experiment_summary['time_slide_id']  = time_slide['time_slide_id']

    # construct an array for the experiment datatype and experiment_id
    # all_data : a zero-lag experiment
    # slide    : a time slide experiment
    if dataset == 'background':
        experiment_summary['datatype'] = np.array(['slide' for i in range(len(time_slide['time_slide_id']))])
        experiment_summary['experiment_id'] = np.array(['experiment:experiment_id:0' for i in range(len(time_slide['time_slide_id']))])
    else:
        experiment_summary['datatype']  = ['all_data']
        experiment_summary['experiment_id'] = ['experiment:experiment_id:0']

    # insert rows into experiment table
    logging.info('Populating experiment_summary table...')
    sqlite_insert_into_table(dbtables.lsctables.ExperimentSummaryTable, experiment_summary)

###############################################################################
# experiment
###############################################################################

# create coinc_event table in database and a dict with column names as key
logging.info('Creating experiment table...')
tmp = sqlite_create_table(dbtables.lsctables.ExperimentTable)

# print
logging.info('Constructing arrays for %s rows in the experiment table...'%dataset)

# construct an array experiment ID, each experiment is an IFO combination
# FIXME: this entire section assumes only a 2-detector analysis
tmp['experiment_id'] = ['experiment:experiment_id:0']

# construct an array for the IFOs in the experiment
tmp['instruments'] = [','.join(ifo_list)]

# construct an array for the start and end time of the experiment
# FIXME: add this

# insert rows into experiment table
logging.info('Populating experiment table...')
sqlite_insert_into_table(dbtables.lsctables.ExperimentTable, tmp)

# save database and exit
logging.info('Done.')
con.commit()
con.close()
sys.exit()




#########################################

# Some notes:

# Need these tables:
#coinc_definer       experiment_map      search_summary      sim_inspiral      
#coinc_event         experiment_summary  search_summvars     sngl_inspiral     
#coinc_event_map     filter              segment             summ_value        
#coinc_inspiral      process             segment_definer     time_slide        
#experiment          process_params      segment_summary     veto_definer    

